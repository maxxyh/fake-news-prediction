{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following this tutorial: https://towardsdatascience.com/multi-class-text-classification-model-comparison-and-selection-5eb066197568\n",
    "# TODO: This tutorial has enhancements: https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f\n",
    "\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A little less than a decade ago, hockey fans w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The writers of the HBO series The Sopranos too...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Despite claims from the TV news outlet to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>After receiving 'subpar' service and experienc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>After watching his beloved Seattle Mariners pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                               text\n",
       "0       1  A little less than a decade ago, hockey fans w...\n",
       "1       1  The writers of the HBO series The Sopranos too...\n",
       "2       1  Despite claims from the TV news outlet to offe...\n",
       "3       1  After receiving 'subpar' service and experienc...\n",
       "4       1  After watching his beloved Seattle Mariners pr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('raw_data/fulltrain.csv', names=['labels', 'text'])\n",
    "test_df = pd.read_csv('raw_data/balancedtest.csv', names=['labels', 'text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "        text: a string\n",
    "        return: modified initial string\n",
    "    \"\"\"\n",
    "    text = str(text).replace(r'http[\\w:/\\.]+','') # removing urls\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwords from text\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "test_df['text'] = test_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y\n",
    "X = df['text']\n",
    "y = df['labels']\n",
    "\n",
    "# test x and y\n",
    "X_test = test_df['text']\n",
    "y_test = test_df['labels']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "my_tags = ['trusted', 'satire', 'hoax', 'propaganda']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "accuracy 0.7886334174797025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.83      0.86      0.85      4244\n",
      "      satire       1.00      0.40      0.57      2065\n",
      "        hoax       0.69      0.99      0.82      5313\n",
      "  propaganda       0.99      0.59      0.74      3035\n",
      "\n",
      "    accuracy                           0.79     14657\n",
      "   macro avg       0.88      0.71      0.74     14657\n",
      "weighted avg       0.84      0.79      0.77     14657\n",
      "\n",
      "TEST SET\n",
      "accuracy 0.511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.69      0.61      0.65       750\n",
      "      satire       0.50      0.01      0.02       750\n",
      "        hoax       0.37      1.00      0.54       750\n",
      "  propaganda       0.98      0.43      0.59       750\n",
      "\n",
      "    accuracy                           0.51      3000\n",
      "   macro avg       0.64      0.51      0.45      3000\n",
      "weighted avg       0.64      0.51      0.45      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "y_pred = nb.predict(X_val)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred, target_names=my_tags))\n",
    "\n",
    "\n",
    "print('TEST SET')\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "accuracy 0.8965681926724433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.84      0.96      0.90      4244\n",
      "      satire       0.97      0.86      0.91      2065\n",
      "        hoax       0.89      0.97      0.93      5313\n",
      "  propaganda       0.98      0.71      0.82      3035\n",
      "\n",
      "    accuracy                           0.90     14657\n",
      "   macro avg       0.92      0.87      0.89     14657\n",
      "weighted avg       0.90      0.90      0.89     14657\n",
      "\n",
      "TEST SET\n",
      "accuracy 0.663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.73      0.77      0.75       750\n",
      "      satire       0.69      0.27      0.38       750\n",
      "        hoax       0.52      0.97      0.68       750\n",
      "  propaganda       0.94      0.64      0.76       750\n",
      "\n",
      "    accuracy                           0.66      3000\n",
      "   macro avg       0.72      0.66      0.64      3000\n",
      "weighted avg       0.72      0.66      0.64      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = Pipeline([('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None)),\n",
    "               ])\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "y_pred = sgd.predict(X_val)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred,target_names=my_tags))\n",
    "\n",
    "\n",
    "print('TEST SET')\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred,target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "accuracy 0.9698437606604353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.97      0.97      0.97      4244\n",
      "      satire       0.97      0.97      0.97      2065\n",
      "        hoax       0.97      0.98      0.98      5313\n",
      "  propaganda       0.96      0.95      0.96      3035\n",
      "\n",
      "    accuracy                           0.97     14657\n",
      "   macro avg       0.97      0.97      0.97     14657\n",
      "weighted avg       0.97      0.97      0.97     14657\n",
      "\n",
      "TEST SET\n",
      "accuracy 0.7676666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.88      0.79      0.83       750\n",
      "      satire       0.78      0.51      0.62       750\n",
      "        hoax       0.66      0.85      0.74       750\n",
      "  propaganda       0.79      0.93      0.85       750\n",
      "\n",
      "    accuracy                           0.77      3000\n",
      "   macro avg       0.78      0.77      0.76      3000\n",
      "weighted avg       0.78      0.77      0.76      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Find optimal hyperparams and score using GridSearchCV\n",
    "parameters = {\n",
    "              'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'tfidf__sublinear_tf': (True, False),\n",
    "              'tfidf__stop_words' : (None, \"english\"),\n",
    "              'tfidf__norm': ('l2', 'l1'),\n",
    "              'clf__class_weight': ('none', \"balanced\", \"auto\"),\n",
    "              'clf__solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "              'clf__penalty': ['none','l2'],\n",
    "              'clf__C': np.logspace(-3,3,7),\n",
    "}\n",
    "\n",
    "# logreg = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "#                    ('clf', LogisticRegression(random_state=0, max_iter=10000)),\n",
    "#                   ])\n",
    "# logreg.fit(X_train, y_train)\n",
    "# gs_clf = GridSearchCV(logreg, parameters, n_jobs=-1, scoring='f1_macro', cv=10)\n",
    "# gs_clf = gs_clf.fit(X_train, y_train)\n",
    "# print(gs_clf.best_params_)\n",
    "# print(gs_clf.best_score_)\n",
    "\n",
    "# Use optimal hyperparams derived from GridSearchCV\n",
    "logreg = Pipeline([('tfidf', TfidfVectorizer(norm='l2', ngram_range=(1,2), sublinear_tf=True, stop_words=\"english\")),\n",
    "                   ('clf', LogisticRegression(class_weight=\"balanced\", solver=\"liblinear\", penalty=\"l2\", C=1000.0)),\n",
    "                  ])\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "y_pred = logreg.predict(X_val)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred, target_names=my_tags))\n",
    "\n",
    "\n",
    "print('TEST SET')\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/07cm72r10wsb6gt_3x9rvgkm0000gn/T/ipykernel_4633/1027683224.py:4: DeprecationWarning: Call to deprecated `init_sims` (Use fill_norms() instead. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  wv.init_sims(replace=True)\n",
      "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n",
      "WARNING:root:cannot compute similarity with no input ['terroristcharlie', 'mcgrath']\n",
      "WARNING:root:cannot compute similarity with no input ['monsantrocity', 'rapyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['corporationyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['theyyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['taipei']\n",
      "WARNING:root:cannot compute similarity with no input ['fcked', 'societyyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['nsas', 'xkeyscore', 'explainedyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['gmos', 'beerliptv']\n",
      "WARNING:root:cannot compute similarity with no input ['ayahuascaresetme']\n",
      "WARNING:root:cannot compute similarity with no input ['kronies', 'rescueyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['voteyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['bitcoin', 'yearsyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['patriotismyoutube']\n",
      "WARNING:root:cannot compute similarity with no input ['abfs', 'daksl']\n"
     ]
    }
   ],
   "source": [
    "# load word vectors \n",
    "from gensim.models import Word2Vec\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"./word_vec/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "wv.init_sims(replace=True)\n",
    "\n",
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.key_to_index:\n",
    "            mean.append(wv.vectors[wv.key_to_index[word]])\n",
    "            all_words.add(wv.key_to_index[word])\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        # FIXME: remove these examples in pre-processing\n",
    "        return np.zeros(wv.vector_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, post) for post in text_list])\n",
    "    \n",
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens\n",
    "\n",
    "train_tokenized = X_train.apply(lambda r: w2v_tokenize_text(r)).values\n",
    "val_tokenized = X_val.apply(lambda r: w2v_tokenize_text(r)).values\n",
    "test_tokenized = X_test.apply(lambda r: w2v_tokenize_text(r)).values\n",
    "\n",
    "X_train_word_average = word_averaging_list(wv, train_tokenized)\n",
    "X_val_word_average = word_averaging_list(wv, val_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv, test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "accuracy 0.8795114962134134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.86      0.89      0.88      4244\n",
      "      satire       0.88      0.81      0.85      2065\n",
      "        hoax       0.89      0.94      0.91      5313\n",
      "  propaganda       0.88      0.80      0.84      3035\n",
      "\n",
      "    accuracy                           0.88     14657\n",
      "   macro avg       0.88      0.86      0.87     14657\n",
      "weighted avg       0.88      0.88      0.88     14657\n",
      "\n",
      "TEST SET\n",
      "accuracy 0.6783333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.75      0.69      0.71       750\n",
      "      satire       0.65      0.40      0.49       750\n",
      "        hoax       0.57      0.86      0.68       750\n",
      "  propaganda       0.81      0.77      0.79       750\n",
      "\n",
      "    accuracy                           0.68      3000\n",
      "   macro avg       0.69      0.68      0.67      3000\n",
      "weighted avg       0.69      0.68      0.67      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, max_iter=10000)\n",
    "logreg = logreg.fit(X_train_word_average, y_train)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "y_pred = logreg.predict(X_val_word_average)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred, target_names=my_tags))\n",
    "\n",
    "\n",
    "print('TEST SET')\n",
    "y_pred = logreg.predict(X_test_word_average)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it was pretty bad... in that case, we shall try..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re\n",
    "\n",
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n",
    "\n",
    "X_train_labelled = label_sentences(X_train, 'Train')\n",
    "X_val_labelled = label_sentences(X_val, 'Val')\n",
    "all_data_train_val = X_train_labelled + X_val_labelled\n",
    "\n",
    "X_test_labelled = label_sentences(X_test, 'Test')\n",
    "all_data_train_test = X_train_labelled + X_test_labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 923585.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1932880.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1734132.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1577517.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1541755.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1817499.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1616393.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1692955.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1644689.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1672163.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48854/48854 [00:00<00:00, 1309796.72it/s]\n",
      "100%|██████████| 37197/37197 [00:00<00:00, 1402651.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1597537.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1754560.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1150361.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1107286.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1528994.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1427746.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1466931.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1593849.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1682579.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37197/37197 [00:00<00:00, 1551112.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_train_val = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow_train_val.build_vocab([x for x in tqdm(all_data_train_val)])\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    model_dbow_train_val.train(utils.shuffle([x for x in tqdm(all_data_train_val)]), total_examples=len(all_data_train_val), epochs=1)\n",
    "    model_dbow_train_val.alpha -= 0.002\n",
    "    model_dbow_train_val.min_alpha = model_dbow_train_val.alpha\n",
    "\n",
    "model_dbow_train_test = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow_train_test.build_vocab([x for x in tqdm(all_data_train_test)])\n",
    "\n",
    "for epoch in range(10):\n",
    "    print(epoch)\n",
    "    model_dbow_train_test.train(utils.shuffle([x for x in tqdm(all_data_train_test)]), total_examples=len(all_data_train_test), epochs=1)\n",
    "    model_dbow_train_test.alpha -= 0.002\n",
    "    model_dbow_train_test.min_alpha = model_dbow_train_test.alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sx/07cm72r10wsb6gt_3x9rvgkm0000gn/T/ipykernel_4633/3599969956.py:13: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  vectors[i] = model.docvecs[prefix]\n"
     ]
    }
   ],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors\n",
    "    \n",
    "train_vectors_dbow_with_val = get_vectors(model_dbow_train_val, len(X_train), 300, 'Train')\n",
    "val_vectors_dbow = get_vectors(model_dbow_train_val, len(X_val), 300, 'Val')\n",
    "\n",
    "train_vectors_dbow_with_test = get_vectors(model_dbow_train_test, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow_train_test, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION SET\n",
      "accuracy 0.9497850856246163\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.95      0.95      0.95      4244\n",
      "      satire       0.96      0.94      0.95      2065\n",
      "        hoax       0.96      0.97      0.96      5313\n",
      "  propaganda       0.94      0.92      0.93      3035\n",
      "\n",
      "    accuracy                           0.95     14657\n",
      "   macro avg       0.95      0.94      0.95     14657\n",
      "weighted avg       0.95      0.95      0.95     14657\n",
      "\n",
      "TEST SET\n",
      "accuracy 0.6896666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     trusted       0.82      0.77      0.79       750\n",
      "      satire       0.66      0.35      0.46       750\n",
      "        hoax       0.55      0.72      0.62       750\n",
      "  propaganda       0.76      0.92      0.83       750\n",
      "\n",
      "    accuracy                           0.69      3000\n",
      "   macro avg       0.70      0.69      0.68      3000\n",
      "weighted avg       0.70      0.69      0.68      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5, random_state=0, max_iter=10000)\n",
    "logreg = logreg.fit(train_vectors_dbow_with_val, y_train)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "y_pred = logreg.predict(val_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "print(classification_report(y_val, y_pred, target_names=my_tags))\n",
    "\n",
    "logreg = logreg.fit(train_vectors_dbow_with_test, y_train)\n",
    "\n",
    "print('TEST SET')\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOW (with Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "\n",
    "X_train_bow = X_train\n",
    "X_val_bow = X_val\n",
    "X_test_bow = X_test\n",
    "\n",
    "y_train_bow = y_train\n",
    "y_val_bow = y_val\n",
    "y_test_bow = y_test\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "tokenize.fit_on_texts(X_train_bow) # only fit on train\n",
    "\n",
    "X_train_bow = tokenize.texts_to_matrix(X_train_bow)\n",
    "X_val_bow = tokenize.texts_to_matrix(X_val_bow)\n",
    "X_test_bow = tokenize.texts_to_matrix(X_test_bow)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train_bow) # only fit on train\n",
    "y_train_bow = encoder.transform(y_train_bow)\n",
    "y_val_bow = encoder.transform(y_val_bow)\n",
    "y_test_bow = encoder.transform(y_test_bow)\n",
    "\n",
    "num_classes = np.max(y_train_bow) + 1\n",
    "y_train_bow = utils.to_categorical(y_train_bow, num_classes)\n",
    "y_val_bow = utils.to_categorical(y_val_bow, num_classes)\n",
    "y_test_bow = utils.to_categorical(y_test_bow, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "962/962 [==============================] - 10s 9ms/step - loss: 0.2909 - accuracy: 0.9022 - val_loss: 0.1597 - val_accuracy: 0.9456\n",
      "Epoch 2/2\n",
      "962/962 [==============================] - 8s 9ms/step - loss: 0.1392 - accuracy: 0.9521 - val_loss: 0.1446 - val_accuracy: 0.9465\n",
      "VALIDATION SET\n",
      "459/459 [==============================] - 2s 4ms/step - loss: 0.1611 - accuracy: 0.9421\n",
      "accuracy: 0.9420754313468933\n",
      "TEST SET\n",
      "94/94 [==============================] - 0s 3ms/step - loss: 1.3814 - accuracy: 0.6777\n",
      "accuracy: 0.6776666641235352\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "history = model.fit(X_train_bow, y_train_bow,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "print('VALIDATION SET')\n",
    "# y_pred = logreg.predict(val_vectors_dbow)\n",
    "\n",
    "# print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
    "# print(classification_report(y_val, y_pred, target_names=my_tags))\n",
    "\n",
    "score_val = model.evaluate(X_val_bow, y_val_bow,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('accuracy:', score_val[1])\n",
    "\n",
    "\n",
    "print('TEST SET')\n",
    "# y_pred = logreg.predict(test_vectors_dbow)\n",
    "\n",
    "# print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "# print(classification_report(y_test, y_pred, target_names=my_tags))\n",
    "\n",
    "score_test = model.evaluate(X_test_bow, y_test_bow,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('accuracy:', score_test[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
